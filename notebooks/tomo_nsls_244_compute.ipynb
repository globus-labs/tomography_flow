{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from globus_compute_sdk import Client, Executor\n",
    "\n",
    "# Define Globus Compute client and function UUID\n",
    "compute_client = Client()\n",
    "endpoint_uuid = \"ae99f53a-1275-48a6-a972-693a80d6c982\"\n",
    "\n",
    "# Define function to run remotely\n",
    "def tomography_reconstruction(proj_file, flat_file, dark_file, angles_file, recon_init, recon_end, rot_center, output_dir):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import os\n",
    "    import h5py\n",
    "    import tomopy\n",
    "\n",
    "    def load_data(proj_file, flat_file, dark_file, angles_file, recon_init, recon_end):\n",
    "        \"\"\"\n",
    "        Loads projection, flat, dark, and angles data from HDF files.\n",
    "        Slices the projection, flat, and dark data between recon_init and recon_end.\n",
    "        Converts the rotation angles to radians.\n",
    "        \"\"\"\n",
    "        with h5py.File(proj_file, 'r') as f_proj:\n",
    "            proj = f_proj['entry']['data']['data'][:, recon_init:recon_end, :]\n",
    "            print('proj', proj.shape, proj.dtype)\n",
    "        with h5py.File(flat_file, 'r') as f_flat:\n",
    "            flats = f_flat['entry']['data']['data'][:, recon_init:recon_end, :]\n",
    "            print('flats', flats.shape, flats.dtype)\n",
    "        with h5py.File(dark_file, 'r') as f_dark:\n",
    "            darks = f_dark['entry']['data']['data'][:, recon_init:recon_end, :]\n",
    "            print('darks', darks.shape, darks.dtype)\n",
    "        with h5py.File(angles_file, 'r') as f_angles:\n",
    "            theta = f_angles['entry']['data']['rotation_angle'][:]\n",
    "            theta = theta * 3.141592653589793 / 180  # convert to radians\n",
    "            print('theta', theta.shape, theta.dtype)\n",
    "        return proj, flats, darks, theta\n",
    "\n",
    "    def recon_data(proj, flats, darks, theta):\n",
    "        \"\"\"\n",
    "        Normalizes the projection data, finds the rotation center,\n",
    "        applies logarithmic normalization, reconstructs the tomographic image,\n",
    "        and applies a circular mask.\n",
    "        \"\"\"\n",
    "        proj_norm = tomopy.normalize(proj, flats, darks)\n",
    "        print('proj_norm', proj_norm.shape, proj_norm.dtype)\n",
    "\n",
    "        # Find rotation center from normalized projections\n",
    "        rot_center = tomopy.find_center_vo(proj_norm)\n",
    "        print('rot_center', rot_center)\n",
    "\n",
    "        # Apply log normalization\n",
    "        proj_log = tomopy.minus_log(proj_norm)\n",
    "        print('proj_norm_ml', proj_log.shape, proj_log.dtype)\n",
    "\n",
    "        # Reconstruct using the gridrec algorithm\n",
    "        recon = tomopy.recon(proj_log, theta, center=rot_center, algorithm='gridrec')\n",
    "        print('recon', recon.shape)\n",
    "\n",
    "        # Apply a circular mask to the reconstruction\n",
    "        recon_masked = tomopy.circ_mask(recon, axis=0, ratio=0.95)\n",
    "\n",
    "        return recon_masked, proj_norm, rot_center\n",
    "\n",
    "    def save_data(recon, rot_center, output_dir='recon'):\n",
    "        \"\"\"\n",
    "        Saves the reconstructed volume as a stack of TIFF files and writes the\n",
    "        rotation center to a text file in the specified output directory.\n",
    "        \"\"\"\n",
    "        import dxchange\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        # Save the reconstruction; files will be written with a prefix in the output directory.\n",
    "        dxchange.write_tiff_stack(recon, fname=os.path.join(output_dir, 'recon'), axis=0)\n",
    "        print('Reconstruction data saved with shape:', recon.shape)\n",
    "\n",
    "        # Save the rotation center to a text file.\n",
    "        center_file = os.path.join(output_dir, 'center.txt')\n",
    "        with open(center_file, 'w') as file:\n",
    "            file.write(str(rot_center))\n",
    "        print('Rotation center saved:', center_file)\n",
    "\n",
    "    def save_images(proj, recon, output_dir='.'):\n",
    "        \"\"\"\n",
    "        Saves representative images of the projection and reconstruction data as PNG files.\n",
    "        \"\"\"\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        proj_img_path = os.path.join(output_dir, 'proj.png')\n",
    "        recon_img_path = os.path.join(output_dir, 'recon.png')\n",
    "\n",
    "        # Save a sinogram (first column of projection data)\n",
    "        plt.imsave(proj_img_path, proj[:, 0, :], cmap='gray')\n",
    "        # Save the middle slice of the reconstruction\n",
    "        mid_slice = recon[recon.shape[0] // 2, :, :]\n",
    "        plt.imsave(recon_img_path, mid_slice, cmap='gray')\n",
    "\n",
    "        print(f\"Projection image saved as {proj_img_path}\")\n",
    "        print(f\"Reconstruction image saved as {recon_img_path}\")\n",
    "\n",
    "    proj, flats, darks, theta = load_data(proj_file, flat_file, dark_file, angles_file, recon_init, recon_end)\n",
    "    recon, proj_norm, rot_center = recon_data(proj, flats, darks, theta)\n",
    "    save_data(recon, rot_center, f'{output_dir}/recon_output')\n",
    "    save_images(proj_norm, recon, f'{output_dir}/recon_output')\n",
    "    \n",
    "    return f\"Reconstruction completed with rot_center: {rot_center}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstruction completed with rot_center: 1609.25\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define base path\n",
    "base_path = '/home/ravescovi/workspace/NSLS2'\n",
    "\n",
    "# Define data parameters\n",
    "data = {\n",
    "    'proj_file': f'{base_path}/scan_00244/proj_00000.hdf',\n",
    "    'angles_file': f'{base_path}/scan_00244/scan_00244.nxs',\n",
    "    'dark_file': f'{base_path}/scan_00245/dark_00000.hdf',\n",
    "    'flat_file': f'{base_path}/scan_00245/flat_00000.hdf',\n",
    "    'recon_init': 1000,\n",
    "    'recon_end': 1512,\n",
    "    'rot_center': None,\n",
    "    'output_dir': f'{base_path}/compute_test'\n",
    "}\n",
    "\n",
    "# Execute function on remote Globus Compute endpoint\n",
    "with Executor(endpoint_id=endpoint_uuid) as gce:\n",
    "    future = gce.submit(tomography_reconstruction, **data)\n",
    "    result = future.result()\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TaskExecutionFailed",
     "evalue": "\n ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n Traceback from attempt: final attempt\n Traceback (most recent call last):\n   File \"/home/ravescovi/miniconda3/envs/tomo/lib/python3.11/concurrent/futures/_base.py\", line 401, in __get_result\n     raise self._exception\n parsl.executors.errors.BadStateException: Executor GlobusComputeEngine-HighThroughputExecutor failed due to: Error 1:\n \tJob is marked as MISSING since the workers failed to register to the executor. Check the stdout/stderr logs in the submit_scripts directory for more debug information\n \tEXIT CODE: 127\n \tSTDOUT: Found cores : 32\n Launching worker: 1\n\n \tSTDERR: Error: runc: runc create failed: unable to start container process: error during container init: exec: \"globus-compute-endpoint\": executable file not found in $PATH: OCI runtime attempted to invoke a command that was not found\n\n\n\n --------------------------------------------------------------------",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTaskExecutionFailed\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 25\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Executor(endpoint_id\u001b[38;5;241m=\u001b[39mendpoint_uuid) \u001b[38;5;28;01mas\u001b[39;00m gce:\n\u001b[1;32m     18\u001b[0m     future \u001b[38;5;241m=\u001b[39m gce\u001b[38;5;241m.\u001b[39msubmit(\n\u001b[1;32m     19\u001b[0m         tomography_reconstruction, \n\u001b[1;32m     20\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdata, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[38;5;66;03m#              'run_dir':'/home/ravescovi'}  \u001b[39;00m\n\u001b[1;32m     24\u001b[0m     )\n\u001b[0;32m---> 25\u001b[0m     result \u001b[38;5;241m=\u001b[39m future\u001b[38;5;241m.\u001b[39mresult()\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(result)\n",
      "File \u001b[0;32m~/miniconda3/envs/tomo/lib/python3.11/concurrent/futures/_base.py:456\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    458\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "File \u001b[0;32m~/miniconda3/envs/tomo/lib/python3.11/concurrent/futures/_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mTaskExecutionFailed\u001b[0m: \n ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n Traceback from attempt: final attempt\n Traceback (most recent call last):\n   File \"/home/ravescovi/miniconda3/envs/tomo/lib/python3.11/concurrent/futures/_base.py\", line 401, in __get_result\n     raise self._exception\n parsl.executors.errors.BadStateException: Executor GlobusComputeEngine-HighThroughputExecutor failed due to: Error 1:\n \tJob is marked as MISSING since the workers failed to register to the executor. Check the stdout/stderr logs in the submit_scripts directory for more debug information\n \tEXIT CODE: 127\n \tSTDOUT: Found cores : 32\n Launching worker: 1\n\n \tSTDERR: Error: runc: runc create failed: unable to start container process: error during container init: exec: \"globus-compute-endpoint\": executable file not found in $PATH: OCI runtime attempted to invoke a command that was not found\n\n\n\n --------------------------------------------------------------------"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define base path\n",
    "base_path = '/home/ravescovi/workspace/NSLS2'\n",
    "\n",
    "# Define data parameters\n",
    "data = {\n",
    "    'proj_file': f'{base_path}/scan_00244/proj_00000.hdf',\n",
    "    'angles_file': f'{base_path}/scan_00244/scan_00244.nxs',\n",
    "    'dark_file': f'{base_path}/scan_00245/dark_00000.hdf',\n",
    "    'flat_file': f'{base_path}/scan_00245/flat_00000.hdf',\n",
    "    'recon_init': 1000,\n",
    "    'recon_end': 1512,\n",
    "    'rot_center': None,\n",
    "    'output_dir': f'{base_path}/test_container'\n",
    "}\n",
    "\n",
    "\n",
    "# Define your container URI (modify this with the correct container image)\n",
    "CONTAINER_URI = \"localhost/tomography-container:latest\"\n",
    "# Execute function on remote Globus Compute endpoint using a container\n",
    "with Executor(endpoint_id=endpoint_uuid) as gce:\n",
    "    future = gce.submit(\n",
    "        tomography_reconstruction, \n",
    "        **data, \n",
    "        ## This will raise an error because it seems globus_compute_sdk does not support user_config\n",
    "        # user_config={'container_type':'podman',\n",
    "        #              'container_uri': CONTAINER_URI,\n",
    "        #              'run_dir':'/home/ravescovi'}  \n",
    "    )\n",
    "    result = future.result()\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tomo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
